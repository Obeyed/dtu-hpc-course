\section{Help}
\label{sec:help}

The style of work for the special course has relied on independent studies.
To facilitate our independent studies we have utilized online learning platforms and online communities to handle questions and challenges.
Below are a listing of our questions posted to the stack overflow community.

\begin{itemize}
  \item Why does shared memory ensure coalesced writes~\footnote{\href{http://stackoverflow.com/questions/34881190/shared-memory-writes-coalesced-writes}{http://stackoverflow.com/questions/34881190/shared-memory-writes-coalesced-writes}}
  \item Debugging out-of-bounds errors~\footnote{\href{http://stackoverflow.com/questions/34898507/cuda-out-of-bounds-write-when-transposing}{http://stackoverflow.com/questions/34898507/cuda-out-of-bounds-write-when-transposing}}
  \item Large values in local memory~\footnote{\href{http://stackoverflow.com/questions/34655893/cuda-large-input-arrays}{http://stackoverflow.com/questions/34655893/cuda-large-input-arrays}}
  \item Developing a reduce algorithm~\footnote{\href{http://stackoverflow.com/questions/34596490/cuda-reduce-algorithm}{http://stackoverflow.com/questions/34596490/cuda-reduce-algorithm}}
\end{itemize}

Furthermore, we have used the GPU Lab at the Technical University of Denmark (DTU) to run our CUDA code.
We connected with \ttt{ssh} to the gpu lab address with our username as 
%
\begin{quote}
  \ttt{ssh {username}@login.gbar.dtu.dk}
\end{quote}
%
To load the needed modules and get access to the correct resources we used the following commands
%
\begin{quote}
  \ttt{qrsh \&\& k40sh \&\& module load cuda}
\end{quote}
%
We compiled our CUDA code with the \ttt{nvcc} compiler and ran it with the following command
%
\begin{quote}
  \ttt{nvcc -arch=sm\_35 -o test cudaCode.cu \&\& ./test}
\end{quote}
%
where \ttt{-arch} defines the compute capability of the device for which we aim to compile the code.
