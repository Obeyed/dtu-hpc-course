\section{Map}
\label{sec:map}

The task of mapping data from some input to some output is a simple task.
The serial code for a mapping operation is presented in \cref{lst:map seq}.
The code loops through each index of the input, and copies the value to the same index in the output.
This operation will take \ttt{SIZE} steps to finish, because we simple loop through all elements.

\begin{lstlisting}[caption={Serial map}, label={lst:map seq}]
void map(int *h_in, int *h_out, int SIZE) {
  for (int j = 0; j < SIZE; j++) 
    h_out[j] = h_in[j];
}
\end{lstlisting}

The nature of the serial solution is an optimal parallel solution.
Every copy operation is independent of the others, which means they can be performed completely in parallel.
We present a simple kernel that perform such a map operation in \cref{lst:map par}.

\begin{lstlisting}[caption={Map kernel}, label={lst:map par}]
__global__ 
void map_kernel(int *d_out, int *d_in, int SIZE) {
  int mid = threadIdx.x + blockDim.x * blockIdx.x;
  if (mid >= SIZE) return;
  d_out[mid] = d_in[mid];
}
\end{lstlisting}

First the kernel calculates the index of thread as a product of its position in the block and grid.
Next, the kernel makes sure that the index is inside the bounds of the arrays, it is operating on.
Finally, the input is copied to the new output.

The step size of the map kernel is 1, because all operations can be performed completely independent of the others.
The work size is equal to \ttt{SIZE} big, because we still need to copy all elements from array to array.

We present the comparison of the map algorithms in \cref{fig:map plot}.
It is clear that the parallel mapping algorithm has an advantage.
All the operations can be performed in parallel, while the CPU has to perform every operation as consecutive operations.

\begin{figure}[htb]
  \centering
  \input{graphics/plots/map}
  \caption{Runtime development of the map algorithms}
  \label{fig:map plot}
\end{figure}
